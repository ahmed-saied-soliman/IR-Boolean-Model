{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import NLTK Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "stop_words = set(stopwords.words('english'))\n",
    "BooleanOperator=[\"And\",\"Or\",\"Not\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readingfromfile():\n",
    "    FilesvsLines={}\n",
    "    NumOfFile=int(input(\"Enter Number Of Files You Will Enter : \"))\n",
    "    for x in range(0,NumOfFile):\n",
    "        NameOfFile=input(\"Enter Name of file : \")\n",
    "        File=open(NameOfFile+\".txt\",'r')\n",
    "        Lines = File.read().splitlines()\n",
    "        FilesvsLines[NameOfFile]=Lines\n",
    "        File.close()\n",
    "    return FilesvsLines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Number Of Files You Will Enter : 4\n",
      "Enter Name of file : DOC1\n",
      "Enter Name of file : DOC2\n",
      "Enter Name of file : DOC3\n",
      "Enter Name of file : DOC4\n",
      "{'DOC1': ['English tutorial'], 'DOC2': ['Advance English'], 'DOC3': ['English Structure'], 'DOC4': ['Tutorial']}\n"
     ]
    }
   ],
   "source": [
    "FilesvsLines=readingfromfile()\n",
    "print(FilesvsLines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitwords(Words):\n",
    "    TWords=[]\n",
    "    for Word in Words:\n",
    "        TWords.extend(word_tokenize(Word))\n",
    "    return TWords    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Stop Words Using Nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeStopWords(words):\n",
    "    filtered_sentence = []\n",
    "    for word in words:\n",
    "        if word not in stop_words:\n",
    "            filtered_sentence.append(word.capitalize())\n",
    "    return filtered_sentence       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Stop Words For Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RemoveStopWordsforQuery(Words):\n",
    "    BooleanOperators=[\"And\",\"Or\",\"Not\",\"and\",\"or\",\"not\"]\n",
    "    for index,word in enumerate(Words):\n",
    "        if word in BooleanOperators:\n",
    "            Words[index]=word\n",
    "        elif word not in stop_words:\n",
    "            Words[index]=word\n",
    "        elif word in stop_words:\n",
    "            Words.remove(word)\n",
    "    return Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['english', 'Ahmed', 'and']\n"
     ]
    }
   ],
   "source": [
    "print(RemoveStopWordsforQuery([\"english\",\"Ahmed\",\"and\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PreprocessingDocuments(FilesvsLines):\n",
    "    for key ,value in FilesvsLines.items():\n",
    "        FilesvsLines[key]=removeStopWords(splitwords(value))\n",
    "    return FilesvsLines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DOC1': ['English', 'Tutorial'], 'DOC2': ['Advance', 'English'], 'DOC3': ['English', 'Structure'], 'DOC4': ['Tutorial']}\n"
     ]
    }
   ],
   "source": [
    "FilesvsLines=PreprocessingDocuments(FilesvsLines)\n",
    "print(FilesvsLines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Term - Document Incidence matrix creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AssignTermIncidenceMatrix(FilesvsLines):\n",
    "    TermWithIncidenceMatrix={}\n",
    "    for value in FilesvsLines.values():\n",
    "        for x in value:\n",
    "            vector=[]\n",
    "            for key in FilesvsLines.keys():\n",
    "                if x in FilesvsLines.get(key):\n",
    "                    vector.append(1)\n",
    "                else:\n",
    "                    vector.append(0)\n",
    "                TermWithIncidenceMatrix[x]=vector  \n",
    "    return TermWithIncidenceMatrix   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'English': [1, 1, 1, 0], 'Tutorial': [1, 0, 0, 1], 'Advance': [0, 1, 0, 0], 'Structure': [0, 0, 1, 0]}\n"
     ]
    }
   ],
   "source": [
    "TermWithIncidenceMatrix=AssignTermIncidenceMatrix(FilesvsLines)\n",
    "print(TermWithIncidenceMatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Term For IncidenceVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetTermIncidenceVector(TermWithIncidenceMatrix,Term):\n",
    "    return TermWithIncidenceMatrix.get(Term)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def QueryPreprocessing(TermWithIncidenceMatrix):\n",
    "    query=input(\"Enter Your Query : \")\n",
    "    #Capitalize each word and split it in Words\n",
    "    queryterm = query.split(\" \")\n",
    "    newquery=RemoveStopWordsforQuery(queryterm)\n",
    "    QueryTerm=[]\n",
    "    for i in newquery:\n",
    "        QueryTerm.append(i.capitalize())\n",
    "    #Removing Words That are not Exist in The Documents\n",
    "    for index,x in enumerate(QueryTerm):\n",
    "        if x in TermWithIncidenceMatrix.keys():\n",
    "            QueryTerm[index]=x\n",
    "        elif x in  BooleanOperator:\n",
    "            QueryTerm[index]=x\n",
    "    return QueryTerm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Your Query : english or Structure\n",
      "['English', 'Or', 'Structure']\n"
     ]
    }
   ],
   "source": [
    "Query=QueryPreprocessing(TermWithIncidenceMatrix)\n",
    "print(Query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Boolean Operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ProcessBooleanOperator(Operation,PreviousTermVector,NextTermVector):\n",
    "    resultVector=[]\n",
    "    if(Operation==\"Not\"):\n",
    "        for index,x in enumerate(PreviousTermVector):\n",
    "            if x==1:\n",
    "                resultVector.append(0)\n",
    "            elif x==0:\n",
    "                resultVector.append(1)\n",
    "    elif(Operation==\"And\"):\n",
    "        for x in range(0,len(PreviousTermVector)):\n",
    "            if(PreviousTermVector[x]==1 and NextTermVector[x]==1):\n",
    "                resultVector.append(1)\n",
    "            else:\n",
    "                resultVector.append(0)\n",
    "    elif(Operation==\"Or\"):\n",
    "        for x in range(0,len(PreviousTermVector)):\n",
    "            if(PreviousTermVector[x]==0 and NextTermVector[x]==0):\n",
    "                resultVector.append(0)\n",
    "            else:\n",
    "                resultVector.append(1)\n",
    "    return resultVector            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ProcessQuery(Query,mydict):\n",
    "    print(Query)\n",
    "    bitWiseOperator=\"\"\n",
    "    previousTermIncidenceV =[]\n",
    "    nextTermIncidenceV =[]\n",
    "    resultSet=[]\n",
    "    hasPreviousTerm = False\n",
    "    hasNotOperation = False\n",
    "    for term in Query:\n",
    "        if(term not in BooleanOperator):\n",
    "            if(hasNotOperation):\n",
    "                if(hasPreviousTerm):\n",
    "                    nextTermIncidenceV = ProcessBooleanOperator(\"NOT\",GetTermIncidenceVector(mydict,term), nextTermIncidenceV)\n",
    "                else:\n",
    "                    previousTermIncidenceV = ProcessBooleanOperator(\"NOT\",GetTermIncidenceVector(mydict,term), nextTermIncidenceV)\n",
    "                hasNotOperation=False    \n",
    "            elif(not hasPreviousTerm):\n",
    "                print(term)\n",
    "                previousTermIncidenceV=GetTermIncidenceVector(mydict,term)\n",
    "                resultSet=previousTermIncidenceV\n",
    "                hasPreviousTerm=True\n",
    "            else:\n",
    "                print(term)\n",
    "                nextTermIncidenceV=GetTermIncidenceVector(mydict,term)\n",
    "        elif(term==\"Not\"):\n",
    "            hasNotOperation=True\n",
    "        else:\n",
    "            print(term)\n",
    "            bitWiseOperator=term\n",
    "        if((nextTermIncidenceV!= []) and (not hasNotOperation)):\n",
    "            print(previousTermIncidenceV)\n",
    "            print(nextTermIncidenceV)\n",
    "            resultSet=ProcessBooleanOperator(bitWiseOperator,previousTermIncidenceV,nextTermIncidenceV)\n",
    "            previousTermIncidenceV=resultSet\n",
    "            hasPreviousTerm=True\n",
    "            nextTermIncidenceV=None\n",
    "    return resultSet        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['English', 'Or', 'Structure']\n",
      "English\n",
      "Or\n",
      "Structure\n",
      "[1, 1, 1, 0]\n",
      "[0, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "dlist=ProcessQuery(Query,TermWithIncidenceMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DetermineDocuments(ResultList,FilesvsLines):\n",
    "    ListOfFiles=list(FilesvsLines.keys())\n",
    "    newList=[]\n",
    "    documents=[]\n",
    "    for index,value in enumerate(ResultList):\n",
    "        if(value ==1):\n",
    "            newList.append(index)\n",
    "    for x in newList:\n",
    "        for y in ListOfFiles:\n",
    "            if(x == ListOfFiles.index(y)):\n",
    "                documents.append(y)\n",
    "    return documents            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DOC1', 'DOC2', 'DOC3']\n"
     ]
    }
   ],
   "source": [
    "print(DetermineDocuments(dlist,FilesvsLines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
